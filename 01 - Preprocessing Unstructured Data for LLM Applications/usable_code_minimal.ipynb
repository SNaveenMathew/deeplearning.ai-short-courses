{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af26f7f-70a8-464f-8cff-5503a18d43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "# If `import chromadb` throws some errors:\n",
    "# import numpy as np\n",
    "# np.float_ = np.float64\n",
    "\n",
    "import json\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json\n",
    "import chromadb\n",
    "\n",
    "# If you're planning to use OpenAI stuff:\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = open(\"../OPENAI_API_KEY.txt\", \"r\").read()# Add your OpenAI API key as text to OPENAI_API_KEY.txt\n",
    "# # But remember, each query is going to be billed to the payment method on the Open AI profile\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "# from langchain_openai import OpenAI# Just kidding\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637000af-1a38-433e-a1f6-2e61ef8ee292",
   "metadata": {},
   "source": [
    "# Use case description\n",
    "\n",
    "Making my blog searchable using unstructured package, some vector database, etc. - probably setting things up for a RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfb41d0-40f0-4be6-bfc1-3ea1edecb891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbznf\\anaconda3\\envs\\dlai-short-courses\\lib\\site-packages\\IPython\\core\\display.py:618: UserWarning: JSON expects JSONable dict or list, not JSON strings\n",
      "  warnings.warn(\"JSON expects JSONable dict or list, not JSON strings\")\n"
     ]
    },
    {
     "data": {
      "application/json": [
       {
        "element_id": "a5832b29dfb9295008cb4ff2a854b47b",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 1
        },
        "text": "layout: post\ndate: 2019-01-11 12:00:00 -0500\nimage: ../data/multiprocessing.jpg",
        "type": "Title"
       },
       {
        "element_id": "65fd38cfbab89c97a35d4d3e019c73bf",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Speeding-up 'diff' between Consecutive Rows in Python on My Laptop",
        "type": "Title"
       },
       {
        "element_id": "b605350bc00209520b7cd8f546322663",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Introduction",
        "type": "Title"
       },
       {
        "element_id": "0dd507109de3540719327b782086dcd0",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "b605350bc00209520b7cd8f546322663"
        },
        "text": "I'm currently pursuing independent research on large financial data. Data engineering is an integral part of the analysis as financial data is often not in the format required for analysis. Financial data may be provided in the form of transactions/updates or in the form of aggregates. While it is easy to go from transaction level to aggregate level, it is difficult to do the opposite.",
        "type": "NarrativeText"
       },
       {
        "element_id": "1b6fec632d0be229a6cc22ae5d8018eb",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "b605350bc00209520b7cd8f546322663"
        },
        "text": "My laptop configuration is decent: Ubuntu 18.04, 16 GB DDR4, Intel core i7–8750H (6 + 6 virtual core) @ 2.2 GHz and a GPU (not relevant here). But brute force is not a good idea — code run time was ~ 4 hours for processing one day's data, which is not acceptable.",
        "type": "NarrativeText"
       },
       {
        "element_id": "636d541c4a0f461e28dea7d07da5b6dc",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Data (samples):",
        "type": "Title"
       },
       {
        "element_id": "03b6b7b94280fc05d4f1a9f51b776dbc",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "636d541c4a0f461e28dea7d07da5b6dc"
        },
        "text": "Without mentioning the type of data, here are few anonymized samples (dy's can be positive or negative):",
        "type": "NarrativeText"
       },
       {
        "element_id": "b2ecd75d456bbcd24707603e78ee77bf",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "636d541c4a0f461e28dea7d07da5b6dc"
        },
        "text": "Note: There can be several consecutive rows that look identical.",
        "type": "NarrativeText"
       },
       {
        "element_id": "0c0b668be128a6f206694ef12e326abe",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Desired outputs for the examples",
        "type": "Title"
       },
       {
        "element_id": "71c60bf4195f4ac93737bc15502f5b2b",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "0c0b668be128a6f206694ef12e326abe"
        },
        "text": "Question: In example 3 how do we know whether y0 is a new value or it is y1+dy1",
        "type": "NarrativeText"
       },
       {
        "element_id": "1060c1143f859748b8a1f7e6b952ac88",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "0c0b668be128a6f206694ef12e326abe"
        },
        "text": "Answer: Other columns (not shown above) in the data set help in identifying the difference.",
        "type": "NarrativeText"
       },
       {
        "element_id": "70f548ec692bb52a98eb8cd67736d5b0",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "0c0b668be128a6f206694ef12e326abe"
        },
        "text": "Note: 0 does not appear in diff, but this is not a difference maker. Hence it is ignored in the solutions.",
        "type": "NarrativeText"
       },
       {
        "element_id": "ae43692b2a310b8ed2443d2b7d2a3e4c",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Properties",
        "type": "Title"
       },
       {
        "element_id": "ef75cefaa984ae8f57315e5bcafdf7f2",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "ae43692b2a310b8ed2443d2b7d2a3e4c"
        },
        "text": "Dataset contains around 1.3 million rows per day.",
        "type": "ListItem"
       },
       {
        "element_id": "8c2c91d51e6279a17a2e53df9dfba6c1",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "ae43692b2a310b8ed2443d2b7d2a3e4c"
        },
        "text": "N is fixed for each row. More than 1 column can be 0.",
        "type": "ListItem"
       },
       {
        "element_id": "3cda4ee75f95cded7da1ae6ba160691c",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "ae43692b2a310b8ed2443d2b7d2a3e4c"
        },
        "text": "It is known that for a data set exactly one of the following will be true:",
        "type": "ListItem"
       },
       {
        "element_id": "ff85ce295f49e5f1c9d8d12c025e5f3c",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "ae43692b2a310b8ed2443d2b7d2a3e4c"
        },
        "text": "y0_id > y1_id > …. > yN_id > 0",
        "type": "ListItem"
       },
       {
        "element_id": "05aaf582ac1adec8a7bcb8d2fadc47eb",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "ae43692b2a310b8ed2443d2b7d2a3e4c"
        },
        "text": "0 < y0_id < y1_id < …. < yN_id",
        "type": "ListItem"
       },
       {
        "element_id": "e0cd2d7145059c6e745c7bb870252f48",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Solutions (processing 1 day)",
        "type": "Title"
       },
       {
        "element_id": "265226df5edd4140ae5c436badea4d43",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "e0cd2d7145059c6e745c7bb870252f48"
        },
        "text": "Note: Codes are illustrative. They are incomplete!",
        "type": "NarrativeText"
       },
       {
        "element_id": "710964e714f40ea09cb19e2a61d90ced",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Brute force",
        "type": "Title"
       },
       {
        "element_id": "1506386002a85bd30c004d84035de70f",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "710964e714f40ea09cb19e2a61d90ced"
        },
        "text": "I believe this one doesn't require explanation. Sample code:",
        "type": "NarrativeText"
       },
       {
        "element_id": "83df8c94937e7d4f56e1061aa4e8d275",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Improvement using pandas",
        "type": "Title"
       },
       {
        "element_id": "4bb9a97a249ad2e8985d2d6e5c0d2198",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "83df8c94937e7d4f56e1061aa4e8d275"
        },
        "text": "This code is similar to the brute force code.",
        "type": "NarrativeText"
       },
       {
        "element_id": "b0f5c143d3572f47c3f309874c62e6e5",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Improved 'search' using dictionary",
        "type": "Title"
       },
       {
        "element_id": "45f41091197cef99f5c966f4fb5d292b",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "b0f5c143d3572f47c3f309874c62e6e5"
        },
        "text": "Idea: look for a matching id and use it for finding difference. Lookup should be quick, so a dictionary can be used with the id value as the key.",
        "type": "NarrativeText"
       },
       {
        "element_id": "00fe253e9991a515f7ecf7f36e3e8078",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Slightly improved 'search': using only 1 loop (both id’s are sorted)",
        "type": "Title"
       },
       {
        "element_id": "3cfc2bdb5716043cdc881d43d813f16d",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "00fe253e9991a515f7ecf7f36e3e8078"
        },
        "text": "Idea: Since both id's are sorted (assumed as descending order in the code below), a single loop can be used to traverse through both id's.",
        "type": "NarrativeText"
       },
       {
        "element_id": "066c45a4b1035033303c31ae86d5f2d6",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "00fe253e9991a515f7ecf7f36e3e8078"
        },
        "text": "Let us iterate through 2 examples:",
        "type": "NarrativeText"
       },
       {
        "element_id": "f6fe4f0c2f6eac942255c1d88f631eea",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Example 1:",
        "type": "Title"
       },
       {
        "element_id": "b7568cc4dca9c3d0fe25e0ba5e296913",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "f6fe4f0c2f6eac942255c1d88f631eea"
        },
        "text": "Iteration 1 (ignore the indexing as Python starts with 0, but column indices start with 1): i=j=0 and the while loop exits at j=0. Id's match and diff is dy1 (non-zero), so 1 row is appended.",
        "type": "NarrativeText"
       },
       {
        "element_id": "b4977d7e9bcc79708e31ce06a03bc7fe",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "f6fe4f0c2f6eac942255c1d88f631eea"
        },
        "text": "Iteration 2: i=1 and while loop exits at j=1. Id's match, but diff=0 — therefore no updates. We're done!",
        "type": "NarrativeText"
       },
       {
        "element_id": "d7f0c6750ed0d333d678edc41917ef80",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Example 2:",
        "type": "Title"
       },
       {
        "element_id": "2c30ccc8da73647e9aa3ce13b654ec6d",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "d7f0c6750ed0d333d678edc41917ef80"
        },
        "text": "Iteration 1: i=j=0 and the while loop exits at j=0. Id’s don’t match, therefore 1 new row is appended.",
        "type": "NarrativeText"
       },
       {
        "element_id": "59fbbe7c8b2ad32f4b216869951ecb6b",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "d7f0c6750ed0d333d678edc41917ef80"
        },
        "text": "Iteration 2: i=1 and the while loop exits at j=0. Id’s match, but diff=0 — therefore no updates. We’re done (kind of, because y2 is not very important in finance \\m/)!",
        "type": "NarrativeText"
       },
       {
        "element_id": "90644dce098ec9604e4ed6b13daddf25",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Ultimatum: multi-processing",
        "type": "Title"
       },
       {
        "element_id": "e3215a5d8b30d553614f0458c518b711",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Run-time Comparison",
        "type": "Title"
       },
       {
        "element_id": "956dd4243bcd8067fc08f0b2a1b09384",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Concatenation — An Additional Problem",
        "type": "Title"
       },
       {
        "element_id": "a1c5ae7bcb34bbf48104488eff8deede",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Problem",
        "type": "Title"
       },
       {
        "element_id": "af666dd14b29e6ceeca39cdc6161f301",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "a1c5ae7bcb34bbf48104488eff8deede"
        },
        "text": "The result is a pandas series of lists. But my desired output is a structure with timestamp + edit in each row. So I used pd.concat(result), which had an additional run time of 3.5 mins (~ clock time for consecutive diff which is a relatively complicated process). This drove me nuts!",
        "type": "NarrativeText"
       },
       {
        "element_id": "22927695994eab589c7601a6b15df4d9",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Solution",
        "type": "Title"
       },
       {
        "element_id": "a5dd0dbf795a85a1272f6825c46c2f51",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "22927695994eab589c7601a6b15df4d9"
        },
        "text": "I found that np.concatenate is much faster (~ 40 sec) because of homogeneity. For simplicity I converted timestamp and all col_idx_values to string. The output was written to a CSV file using np.savetxt(\"file.csv\", concat_result, fmt=\"%s\") or using array_name.tofile(\"file.csv\", sep=\",\", format=\"%s\").",
        "type": "NarrativeText"
       },
       {
        "element_id": "71cc0d3f8db84d73d55bd64224208f7c",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Learnings",
        "type": "Title"
       },
       {
        "element_id": "80090371fa7808c1597abfc8521b497c",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "71cc0d3f8db84d73d55bd64224208f7c"
        },
        "text": "The final solution is a combination of several steps with incremental gains compared to predecessors. Other options such as dask (multiprocessing) were also explored. Ideas related to multi-threading and GPU (CUDA) ended unsuccessfully.",
        "type": "NarrativeText"
       },
       {
        "element_id": "8e76a94ac8320d515375e625bef18292",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2
        },
        "text": "Summary",
        "type": "Title"
       },
       {
        "element_id": "026cacaf4053837b28bf25897edae0ea",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "8e76a94ac8320d515375e625bef18292"
        },
        "text": "Algorithm matters! Gains are in algorithm level. This applies to almost every area of programming.",
        "type": "ListItem"
       },
       {
        "element_id": "50ac07c00eac9931adebb8ccc3fc3fa4",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "8e76a94ac8320d515375e625bef18292"
        },
        "text": "Data can be cleaner than it looks. Patterns in the data can help in faster processing. Eg: multiple delimiters, sorted rows, etc.",
        "type": "ListItem"
       },
       {
        "element_id": "28a763a4a22bd91a212f58f38ac3bb85",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "8e76a94ac8320d515375e625bef18292"
        },
        "text": "Multi-threading in Python is usually not in our hands.",
        "type": "ListItem"
       },
       {
        "element_id": "1f7be972bb2685b2957a9f0e1c084fdf",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "8e76a94ac8320d515375e625bef18292"
        },
        "text": "Multi-processing is cool, but leave 1 core out for safety. Also ensure that there is enough memory to hold a copy of the data frame (+ factor of safety).",
        "type": "ListItem"
       },
       {
        "element_id": "97b766d191c4302e9b64be369ac03c39",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "8e76a94ac8320d515375e625bef18292"
        },
        "text": "Homogeneous data type can leads to faster processing. However, this is not always true.",
        "type": "ListItem"
       },
       {
        "element_id": "5392b96e6151c311d5088a65a294973a",
        "metadata": {
         "file_directory": "../../tech_non_tech_blog/_posts",
         "filename": "2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md",
         "filetype": "text/markdown",
         "languages": [
          "eng"
         ],
         "last_modified": "2025-03-07T20:59:16",
         "page_number": 2,
         "parent_id": "8e76a94ac8320d515375e625bef18292"
        },
        "text": "There may be better (faster / memory efficient) solutions.",
        "type": "ListItem"
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unstructured.partition.md import partition_md\n",
    "filename = \"../../tech_non_tech_blog/_posts/2019-02-02-Speeding-up-diff-between-consecutive-rows-in-python-on-my-laptop.md\"\n",
    "elements = partition_md(filename=filename)\n",
    "element_dict = [el.to_dict() for el in elements]\n",
    "example_output = json.dumps(element_dict, indent=2)\n",
    "JSON(example_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad775a96-e4a9-4faa-bedc-0a10df0a86e2",
   "metadata": {},
   "source": [
    "Write to `chromadb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9291ea0-d2cf-418d-9f46-8406ae46b70d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(path=\"chroma_tmp\", settings=chromadb.Settings(allow_reset=True))\n",
    "client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa8379a-53e5-40f2-8d58-a4ed8f7587b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "    name=\"tech_non_tech_blog\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6a57a2-7bc1-4f4c-95f6-92a25860a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = [\n",
    "    \"Introduction\",\n",
    "    \"Data (samples):\",\n",
    "    \"Desired outputs for the examples\",\n",
    "    \"Properties\",\n",
    "    \"Solutions (processing 1 day)\",\n",
    "    \"Brute force\",\n",
    "    \"Improvement using pandas\",\n",
    "    \"Improved ‘search’ using dictionary\",\n",
    "    \"Slightly improved ‘search’: using only 1 loop (both id’s are sorted)\",\n",
    "    \"Ultimatum: multi-processing\",\n",
    "    \"Run-time Comparison\",\n",
    "    \"Concatenation — An Additional Problem\",\n",
    "    \"Problem\",\n",
    "    \"Solution\",\n",
    "    \"Learnings\",\n",
    "    \"Summary\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938647d3-b395-41c5-b251-d4f773e0ed6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b605350bc00209520b7cd8f546322663': 'Introduction',\n",
       " '636d541c4a0f461e28dea7d07da5b6dc': 'Data (samples):',\n",
       " '0c0b668be128a6f206694ef12e326abe': 'Desired outputs for the examples',\n",
       " 'ae43692b2a310b8ed2443d2b7d2a3e4c': 'Properties',\n",
       " 'e0cd2d7145059c6e745c7bb870252f48': 'Solutions (processing 1 day)',\n",
       " '710964e714f40ea09cb19e2a61d90ced': 'Brute force',\n",
       " '83df8c94937e7d4f56e1061aa4e8d275': 'Improvement using pandas',\n",
       " '90644dce098ec9604e4ed6b13daddf25': 'Ultimatum: multi-processing',\n",
       " 'e3215a5d8b30d553614f0458c518b711': 'Run-time Comparison',\n",
       " '956dd4243bcd8067fc08f0b2a1b09384': 'Concatenation — An Additional Problem',\n",
       " 'a1c5ae7bcb34bbf48104488eff8deede': 'Problem',\n",
       " '22927695994eab589c7601a6b15df4d9': 'Solution',\n",
       " '71cc0d3f8db84d73d55bd64224208f7c': 'Learnings',\n",
       " '8e76a94ac8320d515375e625bef18292': 'Summary'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_ids = {}\n",
    "for element in element_dict:\n",
    "    for chapter in chapters:\n",
    "        try:\n",
    "            if element[\"text\"] == chapter and element[\"type\"] == \"Title\":\n",
    "                chapter_ids[element[\"element_id\"]] = chapter\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "chapter_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e3d1f4-042f-48a6-97ad-f3e10c6ae32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in element_dict:\n",
    "    parent_id = element[\"metadata\"].get(\"parent_id\")\n",
    "    chapter = chapter_ids.get(parent_id, \"\")\n",
    "    collection.add(\n",
    "        documents=[element[\"text\"]],\n",
    "        ids=[element[\"element_id\"]],\n",
    "        metadatas=[{\"chapter\": chapter}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5b791f-15d1-46e4-9d37-eceb2c2c27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Slightly improved 'search': using only 1 loop (both id’s are sorted)\", 'Algorithm matters! Gains are in algorithm level. This applies to almost every area of programming.', \"Without mentioning the type of data, here are few anonymized samples (dy's can be positive or negative):\", '0 < y0_id < y1_id < …. < yN_id', 'Let us iterate through 2 examples:', 'Desired outputs for the examples', \"I'm currently pursuing independent research on large financial data. Data engineering is an integral part of the analysis as financial data is often not in the format required for analysis. Financial data may be provided in the form of transactions/updates or in the form of aggregates. While it is easy to go from transaction level to aggregate level, it is difficult to do the opposite.\", 'Answer: Other columns (not shown above) in the data set help in identifying the difference.', \"I believe this one doesn't require explanation. Sample code:\", \"My laptop configuration is decent: Ubuntu 18.04, 16 GB DDR4, Intel core i7–8750H (6 + 6 virtual core) @ 2.2 GHz and a GPU (not relevant here). But brute force is not a good idea — code run time was ~ 4 hours for processing one day's data, which is not acceptable.\"]\n"
     ]
    }
   ],
   "source": [
    "results = collection.peek()\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c6ee4c-f88b-4b53-b0e9-5cba623786c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ids\": [\n",
      "    [\n",
      "      \"1b6fec632d0be229a6cc22ae5d8018eb\",\n",
      "      \"0dd507109de3540719327b782086dcd0\"\n",
      "    ]\n",
      "  ],\n",
      "  \"distances\": [\n",
      "    [\n",
      "      0.5362240327506318,\n",
      "      0.8606636028930317\n",
      "    ]\n",
      "  ],\n",
      "  \"metadatas\": [\n",
      "    [\n",
      "      {\n",
      "        \"chapter\": \"Introduction\"\n",
      "      },\n",
      "      {\n",
      "        \"chapter\": \"Introduction\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"embeddings\": null,\n",
      "  \"documents\": [\n",
      "    [\n",
      "      \"My laptop configuration is decent: Ubuntu 18.04, 16 GB DDR4, Intel core i7\\u20138750H (6 + 6 virtual core) @ 2.2 GHz and a GPU (not relevant here). But brute force is not a good idea \\u2014 code run time was ~ 4 hours for processing one day's data, which is not acceptable.\",\n",
      "      \"I'm currently pursuing independent research on large financial data. Data engineering is an integral part of the analysis as financial data is often not in the format required for analysis. Financial data may be provided in the form of transactions/updates or in the form of aggregates. While it is easy to go from transaction level to aggregate level, it is difficult to do the opposite.\"\n",
      "    ]\n",
      "  ],\n",
      "  \"uris\": null,\n",
      "  \"data\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"How long did brute force take to process one day's data?\"],\n",
    "    n_results=2,\n",
    "    where={\"chapter\": \"Introduction\"},\n",
    ")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49557f56-11e6-4cd1-bb58-32cc1293b19e",
   "metadata": {},
   "source": [
    "Not very specific, but not a bad result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac2296-bb69-4bb5-826a-ce91d9a4d4a0",
   "metadata": {},
   "source": [
    "## Trying Hugging Face summarization instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0bf3a9-0539-4a45-8b04-c8fe2b08d5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm currently pursuing independent research on large financial data. Data engineering is an integral part of the analysis as financial data is often not in the format required for analysis. Financial data may be provided in the form of transactions/updates or in the form of aggregates. While it is easy to go from transaction level to aggregate level, it is difficult to do the opposite.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_dict[3][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35783d89-d5af-46e2-a571-3ce25216d778",
   "metadata": {},
   "source": [
    "Make sure to run `conda install conda-forge::sentencepiece` before running the next code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd435997-d22b-4cd3-b473-35d09195624e",
   "metadata": {},
   "source": [
    "The following code was copied from https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08bc701-0ad3-48d8-abde-5b70e13f480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\dbznf\\anaconda3\\envs\\dlai-short-courses\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ах и а т і м о х е - мати .\n"
     ]
    }
   ],
   "source": [
    "article_text = element_dict[3][\"text\"]\n",
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [WHITESPACE_HANDLER(article_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"]\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=84,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    ")[0]\n",
    "summary = tokenizer.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e3ef4-e650-40fe-9587-ff65ccfbfe43",
   "metadata": {},
   "source": [
    "Funny! Let's try again with a hardcoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cae9552-2dd5-4b5f-a20a-819265d63c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ах и т а щ і м о х е ща мич я ри - мати .\n"
     ]
    }
   ],
   "source": [
    "article_text = \"\"\"Data engineering is an integral part of the analysis as financial data is often not in the format required for analysis. Financial data may be provided in the form of transactions/updates or in the form of aggregates. While it is easy to go from transaction level to aggregate level, it is difficult to do the opposite.\"\"\"\n",
    "input_ids = tokenizer(\n",
    "    [WHITESPACE_HANDLER(article_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"]\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=84,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    ")[0]\n",
    "summary = tokenizer.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49e603-ce4b-4b70-9b82-9ff882d2a02e",
   "metadata": {},
   "source": [
    "Funny! Choosing a good summarizaiton model is not easy. This will need some fine-tuning or RAG. Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177a6b5-e1c6-40f5-a357-f316ac0eb436",
   "metadata": {},
   "source": [
    "## Trying the retrieval piece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3025bcd-09be-4a2b-88d4-ba29bdc0fe9a",
   "metadata": {},
   "source": [
    "Fortunately this is not the end of the world. There are some open source embedding models. The list along with some code can be found here: https://python.langchain.com/docs/integrations/text_embedding/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8c7f8-ae08-45c6-9cf7-264e3b2d1520",
   "metadata": {},
   "source": [
    "Make sure to run `pip install spacy` before running the next code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352792ce-dd1b-4383-8639-f4d56aed55f1",
   "metadata": {},
   "source": [
    "Also run `python -m spacy download en_core_web_sm` before running the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6715f1-c555-4aaa-89af-2354934781ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = SpacyEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02442028-86a3-43cf-a84a-79b28b981cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for element in elements:\n",
    "    metadata = element.metadata.to_dict()\n",
    "    del metadata[\"languages\"]\n",
    "    metadata[\"source\"] = metadata[\"filename\"]\n",
    "    documents.append(Document(page_content=element.text, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6861c0-da3b-4f1a-9a15-143a6abbecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c69ce8cf-27c8-40f0-af8f-724c550c0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab9fe870-c558-4881-9caa-25b07b941422",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about the articles I wrote in the tech_non_tech_blog.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about articles in the tech_non_tech_blog, politely inform them that you are tuned to only answer questions about tech_non_tech_blog.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85418b4-e9d5-444e-872a-09c67ecbc62f",
   "metadata": {},
   "source": [
    "## OpenLLM\n",
    "\n",
    "OpenLLM doesn't seem to work on Windows. Try again using Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab28f1-667f-4156-85ff-8421c0215e83",
   "metadata": {},
   "source": [
    "Make sure to run `pip install openllm` before running the next code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b1443-1162-4afe-a7a9-62fae041dd50",
   "metadata": {},
   "source": [
    "Still the OpenLLM model doesn't initialize\n",
    "\n",
    "AttributeError: module 'openllm' has no attribute 'Runner'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70e3873c-ee3b-4981-9561-93deb1c1634d",
   "metadata": {},
   "source": [
    "from langchain_community.llms import OpenLLM\n",
    "\n",
    "llm = OpenLLM(\n",
    "    model_name=\"dolly-v2\",\n",
    "    model_id=\"databricks/dolly-v2-3b\",\n",
    "    temperature=0.94,\n",
    "    repetition_penalty=1.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195aab75-48bf-4d15-acb6-e0062726e323",
   "metadata": {},
   "source": [
    "Tried a few things using OpenLLM command line. It doesn't look like OpenLLM works on Windows. Need to switch to Linux and try. WSL doesn't work because for some reason Nvidia GPU isn't recognized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlai-short-courses)",
   "language": "python",
   "name": "dlai-short-courses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
